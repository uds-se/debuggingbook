{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Reducing Failure-Inducing Inputs\n",
    "\n",
    "A standard problem in debugging is this: Your program fails after processing some large input. Only a _part_ of this input, however, is responsible for the failure. _Reducing_ the input to a failure-inducing minimum not only eases debugging – it also helps in understanding why and when the program fails. In this chapter, we present techniques that _automatically reduce and simplify failure-inducing inputs to a minimum_, notably the popular _Delta Debugging_ technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import YouTubeVideo\n",
    "YouTubeVideo(\"6fmJ5l257bM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* Using the \"delta debugging\" technique for reduction has no specific prerequisites.\n",
    "* To understand the `DeltaDebugger` implementation, reading [the chapter on tracing](Tracer.ipynb) is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This chapter is adapted from [a similar chapter in \"The Fuzzing Book\"](https://www.fuzzingbook.org/html/Reducer.html). The material has been adapted to be independent from the `fuzzingbook` infrastructure, to build on general delta debugging (`dd`), and to provide a simpler invocation interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Synopsis\n",
    "<!-- Automatically generated. Do not edit. -->\n",
    "\n",
    "To [use the code provided in this chapter](Importing.ipynb), write\n",
    "\n",
    "```python\n",
    ">>> from debuggingbook.DeltaDebugger import <identifier>\n",
    "```\n",
    "\n",
    "and then make use of the following features.\n",
    "\n",
    "\n",
    "A _reducer_ takes a failure-inducing input and reduces it to the minimum that still reproduces the failure.  This chapter provides a `DeltaDebugger` class that implements such a reducer.\n",
    "\n",
    "Here is a simple example: An arithmetic expression causes an error in the Python interpreter:\n",
    "\n",
    "```python\n",
    ">>> def myeval(inp: str) -> Any:\n",
    ">>>     return eval(inp)\n",
    "\n",
    ">>> with ExpectError(ZeroDivisionError):\n",
    ">>>     myeval('1 + 2 * 3 / 0')\n",
    "```\n",
    "Can we reduce this input to a minimum? _Delta Debugging_ is a simple and robust reduction algorithm. We provide a `DeltaDebugger` class that is used in conjunction with a (failing) function call:\n",
    "\n",
    "```python\n",
    "with DeltaDebugger() as dd:\n",
    "    fun(args...)\n",
    "dd\n",
    "```\n",
    "\n",
    "The class automatically determines minimal arguments that cause the function to fail with the same exception as the original. Printing out the class object reveals the minimized call.\n",
    "\n",
    "```python\n",
    ">>> with DeltaDebugger() as dd:\n",
    ">>>     myeval('1 + 2 * 3 / 0')\n",
    ">>> dd\n",
    "```\n",
    "The input is reduced to the maximum: We get the essence of the division by zero.\n",
    "\n",
    "There also is an interface to access the reduced input(s) programmatically. The method `min_args()` returns a dictionary in which all function arguments are minimized:\n",
    "\n",
    "```python\n",
    ">>> dd.min_args()\n",
    "```\n",
    "In contrast, `max_args()` returns a dictionary in which all function arguments are maximized, but still pass:\n",
    "\n",
    "```python\n",
    ">>> dd.max_args()\n",
    "```\n",
    "The method `min_arg_diff()` returns a triple of \n",
    "* passing input,\n",
    "* failing input, and\n",
    "* their minimal failure-inducing difference:\n",
    "\n",
    "```python\n",
    ">>> dd.min_arg_diff()\n",
    "```\n",
    "And you can also access the function itself, as well as its original arguments.\n",
    "\n",
    "```python\n",
    ">>> dd.function().__name__, dd.args()\n",
    "```\n",
    "`DeltaDebugger` processes (i.e., minimizes or maximizes) all arguments that support a `len()` operation and that can be indexed – notably _strings_ and _lists_. If a function has multiple arguments, all arguments that can be processed will be processed.\n",
    "\n",
    "This chapter also provides a number of superclasses to `DeltaDebugger`, notably `CallCollector`, which obtains the first function call for `DeltaDebugger`. `CallReducer` classes allow for implementing alternate call reduction strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Why Reducing?\n",
    "\n",
    "A common problem in debugging is that given an input, only a _small part of that input may be responsible for the failure_. A central part of debugging is to _identify_ these parts – and to simplify (or _reduce_) the input to a minimal form that reproduces the failure – but does and contains as little else as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here's an example of such a situation.  We have a `mystery()` method that – given its code – can occasionally fail.  But under which circumstances does this actually happen?  We have deliberately obscured the exact condition in order to make this non-obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import bookutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystery(inp: str) -> None:\n",
    "    x = inp.find(chr(0o17 + 0o31))\n",
    "    y = inp.find(chr(0o27 + 0o22))\n",
    "    if x >= 0 and y >= 0 and x < y:\n",
    "        raise ValueError(\"Invalid input\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find an input that causes the function to fail, let us _fuzz_ it – that is, feed it with random inputs – until we find a failing input. There's [entire books about fuzzing](https://fuzzingbook.org); but here, a very simple `fuzz()` function for this purpose will already suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a fuzzer, we need random inputs – and thus a source for randomness. The function `random.randrange(a, b)` returns a random number in the range (a, b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(32, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `random.randrange()` to compose random (printable) characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzz() -> str:\n",
    "    length = random.randrange(10, 70)\n",
    "    fuzz = \"\"\n",
    "    for i in range(length):\n",
    "        fuzz += chr(random.randrange(32, 127))\n",
    "    return fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some random strings produced by our `fuzz()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(repr(fuzz()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use `fuzz()` to find an input where `mistery()` fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    fuzz_input = fuzz()\n",
    "    try:\n",
    "        mystery(fuzz_input)\n",
    "    except ValueError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an input that causes `mystery()` to fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_input = fuzz_input\n",
    "failing_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something in this input causes `mystery()` to fail.  But what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Manual Input Reduction\n",
    "\n",
    "One important step in the debugging process is _reduction_ – that is, to identify those circumstances of a failure that are relevant for the failure to occur, and to _omit_ (if possible) those parts that are not.  As Kernighan and Pike \\cite{Kernighan1999} put it:\n",
    "\n",
    "> For every circumstance of the problem, check whether it is relevant for the problem to occur.  If it is not, remove it from the problem report or the test case in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically for inputs, they suggest a _divide and conquer_ process:\n",
    "\n",
    "> Proceed by binary search.  Throw away half the input and see if the output is still wrong; if not, go back to the previous state and discard the other half of the input.\n",
    "\n",
    "This is something we can easily try out, using our last generated input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can see whether the error still occurs if we only feed in the first half:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_length = len(failing_input) // 2   # // is integer division\n",
    "first_half = failing_input[:half_length]\n",
    "first_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(first_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope – the first half alone does not suffice.  Maybe the second half?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half = failing_input[half_length:]\n",
    "assert first_half + second_half == failing_input\n",
    "second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(second_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not go so well either.  We may still proceed by cutting away _smaller chunks_ – say, one character after another.  If our test is deterministic and easily repeated, it is clear that this process eventually will yield a reduced input.  But still, it is a rather inefficient process, especially for long inputs.  What we need is a _strategy_ that effectively minimizes a failure-inducing input – a strategy that can be automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to effectively reduce failure-inducing inputs is _delta debugging_ \\cite{Zeller2002}.  Delta Debugging implements the \"binary search\" strategy, as listed above, but with a twist: If neither half fails (also as above), it keeps on cutting away smaller and smaller chunks from the input, until it eliminates individual characters.  Thus, after cutting away the first half, we cut away\n",
    "the first quarter, the second quarter, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this on our example, and see what happens if we cut away the first quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_length = len(failing_input) // 4\n",
    "input_without_first_quarter = failing_input[quarter_length:]\n",
    "input_without_first_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(input_without_first_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! This has failed, and reduced our failing input by 25%.  Let's remove another quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter = failing_input[quarter_length * 2:]\n",
    "input_without_first_and_second_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(input_without_first_and_second_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too surprising, as we had that one before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing the third quarter, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_third_quarter = failing_input[quarter_length:\n",
    "                                                      quarter_length * 2] + failing_input[quarter_length * 3:]\n",
    "input_without_first_and_third_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    mystery(input_without_first_and_third_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!  This has succeeded.  Our input is now 50% smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now tried to remove pieces that make up $\\frac{1}{2}$ and $\\frac{1}{4}$ of the original failing string.  In the next iteration, we would go and remove even smaller pieces – $\\frac{1}{8}$, $\\frac{1}{16}$ and so on.  We continue until we are down to $\\frac{1}{26}$ – that is, individual characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is something we happily let a computer do for us – and this is what the _Delta Debugging_ algorithm does.  Delta Debugging implements the strategy sketched above: It first removes larger chunks of size $\\frac{1}{2}$; if this does not fail, then we proceed to chunks of size $\\frac{1}{4}$, then $\\frac{1}{8}$ and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `ddmin()` implementation uses almost the same Python code as Zeller in \\cite{Zeller2002}; the only difference is that it has been adapted to work on Python 3.  The variable `n` (initially 2) indicates the granularity – in each step, chunks of size $\\frac{1}{n}$ are cut away.  If none of the test fails (`some_complement_is_failing` is False), then `n` is doubled – until it reaches the length of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASS = 'PASS'\n",
    "FAIL = 'FAIL'\n",
    "UNRESOLVED = 'UNRESOLVED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Any, Callable, Optional, Type, Tuple, Any\n",
    "from typing import Dict, Union, Set, List, FrozenSet, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddmin(test: Callable, inp: Sequence, *test_args: Any) -> Sequence:\n",
    "    \"\"\"Reduce the input inp, using the outcome of test(fun, inp).\"\"\"\n",
    "    assert test(inp, *test_args) != PASS\n",
    "\n",
    "    n = 2     # Initial granularity\n",
    "    while len(inp) >= 2:\n",
    "        start = 0\n",
    "        subset_length = int(len(inp) / n)\n",
    "        some_complement_is_failing = False\n",
    "\n",
    "        while start < len(inp):\n",
    "            complement = (inp[:int(start)] + inp[int(start + subset_length):])  # type: ignore\n",
    "\n",
    "            if test(complement, *test_args) == FAIL:\n",
    "                inp = complement\n",
    "                n = max(n - 1, 2)\n",
    "                some_complement_is_failing = True\n",
    "                break\n",
    "\n",
    "            start += subset_length\n",
    "\n",
    "        if not some_complement_is_failing:\n",
    "            if n == len(inp):\n",
    "                break\n",
    "            n = min(n * 2, len(inp))\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how `ddmin()` works, let us run it on our failing input. We need to define a `test` function that returns PASS or FAIL, depending on the test outcome. This `generic_test()` assumes that the function fails if it raises an exception (such as an `AssertException`), and passes otherwise. The optional argument `expected_exc` specifies the name of exception to be checked for; this ensures we reduce only for the kind of error raised in the original failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_test(inp: Sequence, fun: Callable,\n",
    "                 expected_exc: Optional[Type] = None) -> str:\n",
    "    result = None\n",
    "    detail = \"\"\n",
    "    try:\n",
    "        result = fun(inp)\n",
    "        outcome = PASS\n",
    "    except Exception as exc:\n",
    "        detail = f\" ({type(exc).__name__}: {str(exc)})\"\n",
    "        if expected_exc is None:\n",
    "            outcome = FAIL\n",
    "        elif type(exc) == type(expected_exc) and str(exc) == str(expected_exc):\n",
    "            outcome = FAIL\n",
    "        else:\n",
    "            outcome = UNRESOLVED\n",
    "\n",
    "    print(f\"{fun.__name__}({repr(inp)}): {outcome}{detail}\")\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke `ddmin()` in our setting. With each step, we see how the remaining input gets smaller and smaller, until only two characters remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddmin(generic_test, failing_input, mystery, ValueError('Invalid input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know why `mystery()` fails – it suffices that the input contains two matching parentheses.  Delta Debugging determines this in 25 steps.  Its result is _1-minimal_, meaning that every character contained is required to produce the error; removing any (as seen in the last two tests, above) no longer causes the test to fail.  This property is guaranteed by the delta debugging algorithm, which in its last stage always tries to delete characters one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "A reduced test case such as the one above has many advantages:\n",
    "\n",
    "* A reduced test case __reduces the _cognitive load_ of the programmer__.  The test case is shorter and focused, and thus does not burden the programmer with irrelevant details.  A reduced input typically leads to shorter executions and smaller program states, both of which reduce the search space as it comes to understanding the bug.  In our case, we have eliminated lots of irrelevant input – only the two characters the reduced input contains are relevant.\n",
    "\n",
    "* A reduced test case __is easier to communicate__.  All one needs here is the summary: `mystery() fails on \"()\"`, which is much better than `mystery() fails on a 4100-character input (attached)`.\n",
    "\n",
    "* A reduced test case helps in __identifying duplicates__.  If similar bugs have been reported already, and all of them have been reduced to the same cause (namely that the input contains matching parentheses), then it becomes obvious that all these bugs are different symptoms of the same underlying cause – and would all be resolved at once with one code fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How effective is delta debugging?  In the best case (when the left half or the right half fails), the number of tests is logarithmic proportional to the length $n$ of an input (i.e., $O(\\log_2 n)$); this is the same complexity as binary search.  In the worst case, though, delta debugging can require a number of tests proportional to $n^2$  (i.e., $O(n^2)$) – this happens in the case when we are down to character granularity, and we have to repeatedly tried to delete all characters, only to find that deleting the last character results in a failure \\cite{Zeller2002}.  (This is a pretty pathological situation, though.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, delta debugging is a robust algorithm that is easy to implement, easy to deploy, and easy to use – provided that the underlying test case is deterministic and runs quickly enough to warrant a number of experiments. In general, any debugging task should start with simplifying the test case as much as possible – and this is where delta debugging can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple DeltaDebugger Interface\n",
    "\n",
    "As defined above, using `ddmin()` still requires the developer to set up a special testing function – and writing or using even a generic tester (like `generic_test()`) takes some effort.  We want to simplify the setup such that only two lines of Python is required.\n",
    "\n",
    "Our aim is to have a `DeltaDebugger` class that we can use in conjunction with a failing (i.e., exception raising) function call:\n",
    "\n",
    "```python\n",
    "with DeltaDebugger() as dd:\n",
    "    mystery(failing_input)\n",
    "dd\n",
    "```\n",
    "Here, at the end of the `with` statement, printing out `dd` shows us the minimal input that causes the failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excursion: Implementing DeltaDebugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our interface consist of six building blocks:\n",
    "\n",
    "1. We collect the name and args of the first call in the `with` body, as well as the exception it raises.\n",
    "2. We set up an infrastructure such that we can repeat calls with different arguments.\n",
    "3. We make sure that multiple tests with the same arguments can return outcomes from a cache.\n",
    "4. We create a `DeltaDebugger` class that implements the general Delta Debugging algorithm – an algorithm than can minimize failing inputs as well as maximize passing inputs.\n",
    "5. We provide an infrastructure that applies Delta Debugging on multiple arguments.\n",
    "6. Finally, custom methods like `min_args()` allow to invoke delta debugging on arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting a Call\n",
    "\n",
    "We start by creating an infrastructure that collects a call. The `CallCollector` class saves the first call observed in `_function`, `_args`, and `_exception` attributes, respectively; it then turns tracing off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import FunctionType, FrameType, TracebackType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StackInspector import StackInspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoCallError(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallCollector(StackInspector):\n",
    "    \"\"\"\n",
    "    Collect an exception-raising function call f().\n",
    "    Use as `with CallCollector(): f()`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize collector\"\"\"\n",
    "        self.init()\n",
    "\n",
    "    def init(self) -> None:\n",
    "        \"\"\"Reset for new collection.\"\"\"\n",
    "        self._function: Optional[Callable] = None\n",
    "        self._args: Dict[str, Any] = {}\n",
    "        self._exception: Optional[BaseException] = None\n",
    "        self.original_trace_function: Optional[Callable] = None\n",
    "\n",
    "    def traceit(self, frame: FrameType, event: str, arg: Any) -> None:\n",
    "        \"\"\"Tracing function. Collect first call, then turn tracing off.\"\"\"\n",
    "        if event == 'call':\n",
    "            name = frame.f_code.co_name\n",
    "            if name.startswith('__'):\n",
    "                # Internal function\n",
    "                return\n",
    "            if self._function is not None:\n",
    "                # Already set\n",
    "                return\n",
    "\n",
    "            func = self.search_func(name, frame)\n",
    "            if func:\n",
    "                self._function = func\n",
    "            else:\n",
    "                # Create new function from given code\n",
    "                self._function = self.create_function(frame)\n",
    "\n",
    "            self._args = {}  # Create a local copy of args\n",
    "            for var in frame.f_locals:\n",
    "                if var in frame.f_code.co_freevars:\n",
    "                    continue  # Local var, not an argument\n",
    "                self._args[var] = frame.f_locals[var]\n",
    "\n",
    "            # Turn tracing off\n",
    "            sys.settrace(self.original_trace_function)\n",
    "\n",
    "    def after_collection(self) -> None:\n",
    "        \"\"\"Called after collection. To be defined in subclasses.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def args(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return the dictionary of collected arguments.\"\"\"\n",
    "        return self._args\n",
    "\n",
    "    def function(self) -> Callable:\n",
    "        \"\"\"Return the function called.\"\"\"\n",
    "        if self._function is None:\n",
    "            raise NoCallError(\"No function call collected\")\n",
    "        return self._function\n",
    "\n",
    "    def exception(self) -> Optional[BaseException]:\n",
    "        \"\"\"Return the exception produced, or `None` if none.\"\"\"\n",
    "        return self._exception\n",
    "\n",
    "    def format_call(self, args: Optional[Dict[str, Any]] = None) -> str:\n",
    "        ...\n",
    "\n",
    "    def format_exception(self, exc: Optional[BaseException] = None) -> str:\n",
    "        ...\n",
    "\n",
    "    def call(self, new_args: Optional[Dict[str, Any]] = None) -> Any:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CallCollector` is used like a `Tracer` from the [chapter on tracing](Tracer.ipynb), using a `with` block to collect a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallCollector(CallCollector):\n",
    "    def __enter__(self) -> Any:\n",
    "        \"\"\"Called at begin of `with` block. Turn tracing on.\"\"\"\n",
    "        self.init()\n",
    "        self.original_trace_function = sys.gettrace()\n",
    "        sys.settrace(self.traceit)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_tp: Type, exc_value: BaseException,\n",
    "                 exc_traceback: TracebackType) -> Optional[bool]:\n",
    "        \"\"\"Called at end of `with` block. Turn tracing off.\"\"\"\n",
    "        sys.settrace(self.original_trace_function)\n",
    "\n",
    "        if not self._function:\n",
    "            if exc_tp:\n",
    "                return False  # re-raise exception\n",
    "            else:\n",
    "                raise NoCallError(\"No call collected\")\n",
    "\n",
    "        if self.is_internal_error(exc_tp, exc_value, exc_traceback):\n",
    "            return False  # Re-raise exception\n",
    "\n",
    "        self._exception = exc_value\n",
    "        self.after_collection()\n",
    "        return True  # Ignore exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the attributes as collected by `CallCollector` for our `mystery()` function. Note that the `mystery()` exception is \"swallowed\" by the `CallCollector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallCollector() as call_collector:\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an error occurs _before_ the first function call takes place, the exception is simply re-raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(NameError):\n",
    "    with CallCollector() as c:\n",
    "        some_error()  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating a Call\n",
    "\n",
    "Our second step is an infrastructure such that we can call the function collected earlier with alternate arguments. We can call the function directly via the collected `_function` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.function()(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    call_collector.function()(failing_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide the arguments collected during the call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ValueError):\n",
    "    call_collector.function()(**call_collector.args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `call()` method calls the collected function using this construct. It also allows to _change_ individual arguments by providing a `new_args` dictionary of variable names to new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallCollector(CallCollector):\n",
    "    def call(self, new_args: Optional[Dict[str, Any]] = None) -> Any:\n",
    "        \"\"\"\n",
    "        Call collected function. If `new_args` is given,\n",
    "        override arguments from its {var: value} entries.\n",
    "        \"\"\"\n",
    "\n",
    "        if new_args is None:\n",
    "            new_args = {}\n",
    "\n",
    "        args = {}  # Create local copy\n",
    "        for var in self.args():\n",
    "            args[var] = self.args()[var]\n",
    "        for var in new_args:\n",
    "            args[var] = new_args[var]\n",
    "\n",
    "        return self.function()(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using simply `call()` without arguments reproduces the failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallCollector() as call_collector:\n",
    "    mystery(failing_input)\n",
    "with ExpectError(ValueError):\n",
    "    call_collector.call()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also supply alternate arguments (and get alternate outcomes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.call({'inp': 'foo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We close with two helper functions that come handy for logging and error messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallCollector(CallCollector):\n",
    "    def format_call(self, args: Optional[Dict[str, Any]] = None) -> str:\n",
    "        \"\"\"Return a string representing a call of the function with given args.\"\"\"\n",
    "        if args is None:\n",
    "            args = self.args()\n",
    "        return self.function().__name__ + \"(\" + \\\n",
    "            \", \".join(f\"{arg}={repr(args[arg])}\" for arg in args) + \")\"\n",
    "\n",
    "    def format_exception(self, exc: Optional[BaseException] = None) -> str:\n",
    "        \"\"\"Return a string representing the given exception.\"\"\"\n",
    "        if exc is None:\n",
    "            exc = self.exception()\n",
    "        s = type(exc).__name__\n",
    "        if str(exc):\n",
    "            s += \": \" + str(exc)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallCollector() as call_collector:\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.format_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_collector.format_exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing, Logging, and Caching\n",
    "\n",
    "Our next to last step is an infrastructure that implements delta debugging for the collected call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first introduce a `CallReducer` class as an abstract superclass for all kinds of reducers.\n",
    "Its `run()` method tests the function and returns PASS, FAIL, or UNRESOLVED. As with `generic_test()`, above, we check for exception type and exact error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallReducer(CallCollector):\n",
    "    def __init__(self, log: Union[bool, int] = False) -> None:\n",
    "        \"\"\"Initialize. If `log` is True, enable logging.\"\"\"\n",
    "        super().__init__()\n",
    "        self.log = log\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the number of tests.\"\"\"\n",
    "        self.tests = 0\n",
    "\n",
    "    def run(self, args: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Run collected function with `args`. Return\n",
    "        * PASS if no exception occurred\n",
    "        * FAIL if the collected exception occurred\n",
    "        * UNRESOLVED if some other exception occurred.\n",
    "        Not to be used directly; can be overloaded in subclasses.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = self.call(args)\n",
    "        except Exception as exc:\n",
    "            self.last_exception = exc\n",
    "            if (type(exc) == type(self.exception()) and\n",
    "                    str(exc) == str(self.exception())):\n",
    "                return FAIL\n",
    "            else:\n",
    "                return UNRESOLVED  # Some other failure\n",
    "\n",
    "        self.last_result = result\n",
    "        return PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test()` method runs a single test (with logging, if wanted); the `reduce_arg()` method will eventually reduce an input to the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallReducer(CallReducer):\n",
    "    def test(self, args: Dict[str, Any]) -> str:\n",
    "        \"\"\"Like run(), but also log detail and keep statistics.\"\"\"\n",
    "        outcome = self.run(args)\n",
    "        if outcome == PASS:\n",
    "            detail = \"\"\n",
    "        else:\n",
    "            detail = f\" ({self.format_exception(self.last_exception)})\"\n",
    "\n",
    "        self.tests += 1\n",
    "        if self.log:\n",
    "            print(f\"Test #{self.tests} {self.format_call(args)}: {outcome}{detail}\")\n",
    "\n",
    "        return outcome\n",
    "\n",
    "    def reduce_arg(self, var_to_be_reduced: str, args: Dict[str, Any]) -> Sequence:\n",
    "        \"\"\"\n",
    "        Determine and return a minimal value for var_to_be_reduced.\n",
    "        To be overloaded in subclasses.\n",
    "        \"\"\"\n",
    "        return args[var_to_be_reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some logging output from the `test()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallReducer(log=True) as reducer:\n",
    "    mystery(failing_input)\n",
    "\n",
    "reducer.test({'inp': failing_input})\n",
    "reducer.test({'inp': '123'})\n",
    "reducer.test({'inp': '123'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CachingCallReducer` variant saves test results, such that we don't have to run the same tests again and again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachingCallReducer(CallReducer):\n",
    "    \"\"\"Like CallReducer, but cache test outcomes.\"\"\"\n",
    "\n",
    "    def init(self) -> None:\n",
    "        super().init()\n",
    "        self._cache: Dict[FrozenSet, str] = {}\n",
    "\n",
    "    def test(self, args: Dict[str, Any]) -> str:\n",
    "        # Create a hashable index\n",
    "        try:\n",
    "            index = frozenset((k, v) for k, v in args.items())\n",
    "        except TypeError:\n",
    "            index = frozenset()\n",
    "\n",
    "        if not index:\n",
    "            # Non-hashable value – do not use cache\n",
    "            return super().test(args)\n",
    "\n",
    "        if index in self._cache:\n",
    "            return self._cache[index]\n",
    "\n",
    "        outcome = super().test(args)\n",
    "        self._cache[index] = outcome\n",
    "\n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now repeat a test with the same argument, its outcome can be found in the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CachingCallReducer(log=True) as reducer:\n",
    "    mystery(failing_input)\n",
    "\n",
    "reducer.test({'inp': failing_input})\n",
    "reducer.test({'inp': '123'})\n",
    "reducer.test({'inp': '123'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Delta Debugging\n",
    "\n",
    "The `DeltaDebugger` class finally implements Delta Debugging on arguments. Our implementation uses the _general_ `dd()` delta debugging algorithm from \\cite{Zeller2002}. In contrast to `ddmin()`, it returns a _pair_ of a maximized passing input and a minimized failing input. The algorithm can be customized, however, to leave the passing input fixed and _only_ to minimize the failing input (as with `ddmin()`), or vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, `dd()` does not directly work on a list of elements; instead, it works on sets of _indices_ into such a list. The function `to_set()` converts a collection into such a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_set(inp: Sequence) -> Set:\n",
    "    \"\"\"Convert inp into a set of indices\"\"\"\n",
    "    return set(range(len(inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_set(\"abcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `from_set()` converts a set of indices back into the original collection. For this, it uses a function `empty()` that returns an empty collection that has the same type as the given input `inp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty(inp: Any) -> Any:\n",
    "    \"\"\"Return an \"empty\" element of the same type as inp\"\"\"\n",
    "    return type(inp)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty(\"abc\"), empty([1, 2, 3]), empty({0, -1, -2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `add_to()` tries out various ways to add an element to a given collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to(collection: Any, elem: Any) -> Any:\n",
    "    \"\"\"Add element to collection; return new collection.\"\"\"\n",
    "    if isinstance(collection, str):\n",
    "        return collection + elem  # Strings\n",
    "\n",
    "    try:  # Lists and other collections\n",
    "        return collection + type(collection)([elem])\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    try:  # Sets\n",
    "        return collection | type(collection)([elem])\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(\"Cannot add element to collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to(\"abc\", \"d\"), add_to([1, 2, 3], 4), add_to(set([1, 2, 3]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `empty()` and `add_to()`, we can now implement `from_set()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_set(the_set: Any, inp: Sequence) -> Any:\n",
    "    \"\"\"Convert a set of indices into `inp` back into a collection.\"\"\"\n",
    "    ret = empty(inp)\n",
    "    for i, c in enumerate(inp):\n",
    "        if i in the_set:\n",
    "            ret = add_to(ret, c)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_set({1, 2}, \"abcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split a set of elements into `n` subsets of equal size, we use this helper function, based on [this discussion in StackOverflow](https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length/37414115#37414115)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(elems: Any, n: int) -> List:\n",
    "    assert 1 <= n <= len(elems)\n",
    "\n",
    "    k, m = divmod(len(elems), n)\n",
    "    try:\n",
    "        subsets = list(elems[i * k + min(i, m):(i + 1) * k + min(i + 1, m)]\n",
    "                       for i in range(n))\n",
    "    except TypeError:\n",
    "        # Convert to list and back\n",
    "        subsets = list(type(elems)(\n",
    "                    list(elems)[i * k + min(i, m):(i + 1) * k + min(i + 1, m)])\n",
    "                       for i in range(n))\n",
    "\n",
    "    assert len(subsets) == n\n",
    "    assert sum(len(subset) for subset in subsets) == len(elems)\n",
    "    assert all(len(subset) > 0 for subset in subsets)\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 8):\n",
    "    print(split([1, 2, 3, 4, 5, 6, 7], n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split(\"abcd\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split({1, 2, 3, 4, 5, 6, 7}, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can now implement general delta debugging. Our implementation follows \\cite{Zeller2002} with the following optimizations:\n",
    "\n",
    "* We can control whether only to minimize or to maximize (\"mode\")\n",
    "* The operations \"Reduce to subset\" and \"Increase to subset\" are only taken while the number of subsets is still 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(CachingCallReducer):\n",
    "    def dd(self, var_to_be_reduced: str, fail_args: Dict[str, Any], mode: str = '-') -> \\\n",
    "                Tuple[Sequence, Sequence, Sequence]:\n",
    "        \"\"\"General Delta Debugging.\n",
    "        fail_args - a dict of (failure-inducing) function arguments;\n",
    "        fail_args[var_to_be_reduced] - the input to apply dd on.\n",
    "        mode tells how the algorithm should operate:\n",
    "            '-': minimize input (ddmin),\n",
    "            '+': maximizing input (ddmax),\n",
    "            '+-': minimizing pass/fail difference (dd)\n",
    "        Returns a triple (pass, fail, diff) \n",
    "        with maximized passing input, minimized failing input,\n",
    "        and their difference (elems in fail, but not in pass).\n",
    "        \"\"\"\n",
    "        def test(c: Set) -> str:\n",
    "            # Set up args\n",
    "            test_args = {}\n",
    "            for var in fail_args:\n",
    "                test_args[var] = fail_args[var]\n",
    "            test_args[var_to_be_reduced] = from_set(c, fail_inp)\n",
    "            return self.test(test_args)\n",
    "\n",
    "        def ret(c_pass: Set, c_fail: Set) -> \\\n",
    "            Tuple[Sequence, Sequence, Sequence]:\n",
    "            return (from_set(c_pass, fail_inp),\n",
    "                    from_set(c_fail, fail_inp),\n",
    "                    from_set(c_fail - c_pass, fail_inp))\n",
    "\n",
    "        n = 2  # Initial granularity\n",
    "\n",
    "        fail_inp = fail_args[var_to_be_reduced]\n",
    "\n",
    "        c_pass = to_set([])\n",
    "        c_fail = to_set(fail_inp)\n",
    "        offset = 0\n",
    "\n",
    "        minimize_fail = '-' in mode\n",
    "        maximize_pass = '+' in mode\n",
    "\n",
    "        while True:\n",
    "            if self.log > 1:\n",
    "                print(\"Passing input:\", repr(from_set(c_pass, fail_inp)))\n",
    "                print(\"Failing input:\", repr(from_set(c_fail, fail_inp)))\n",
    "\n",
    "            delta = c_fail - c_pass\n",
    "            if len(delta) < n:\n",
    "                return ret(c_pass, c_fail)\n",
    "\n",
    "            deltas = split(delta, n)\n",
    "\n",
    "            j = 0\n",
    "            while j < n:\n",
    "                i = (j + offset) % n\n",
    "                next_c_pass = c_pass | deltas[i]\n",
    "                next_c_fail = c_fail - deltas[i]\n",
    "\n",
    "                if minimize_fail and n == 2 and test(next_c_pass) == FAIL:\n",
    "                    if self.log > 1:\n",
    "                        print(\"Reduce to subset\")\n",
    "                    c_fail = next_c_pass\n",
    "                    # n = 2\n",
    "                    offset = 0\n",
    "                    break\n",
    "                elif maximize_pass and n == 2 and test(next_c_fail) == PASS:\n",
    "                    if self.log > 1:\n",
    "                        print(\"Increase to subset\")\n",
    "                    c_pass = next_c_fail\n",
    "                    # n = 2\n",
    "                    offset = 0\n",
    "                    break\n",
    "                elif minimize_fail and test(next_c_fail) == FAIL:\n",
    "                    if self.log > 1:\n",
    "                        print(\"Reduce to complement\")\n",
    "                    c_fail = next_c_fail\n",
    "                    n = max(n - 1, 2)\n",
    "                    offset = i\n",
    "                    break\n",
    "                elif maximize_pass and test(next_c_pass) == PASS:\n",
    "                    if self.log > 1:\n",
    "                        print(\"Increase to complement\")\n",
    "                    c_pass = next_c_pass\n",
    "                    n = max(n - 1, 2)\n",
    "                    offset = i\n",
    "                    break\n",
    "                else:\n",
    "                    j += 1  # choose next subset\n",
    "\n",
    "            if j >= n:  # no reduction found\n",
    "                if n >= len(delta):\n",
    "                    return ret(c_pass, c_fail)\n",
    "\n",
    "                n = min(n + 2, len(delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `dd()` minimizes inputs – just like `ddmin()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its output is a pair of maximized passing input (if wanted) and minimized failing input. Here's the minimized failing input for `mystery()`, just as with `ddmin()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.dd('inp', {'inp': failing_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We will introduce more comfortable APIs later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can follow the operation of `dd()` by increasing the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=2) as dd:\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.dd('inp', {'inp': failing_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Multiple Arguments\n",
    "\n",
    "What happens if a function has multiple arguments? First, we check if they are _reducible_ – that is, they provide a `len()` length function and a way to access indexed elements. This holds for all strings and all lists, as well as other ordered collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_reducible(value: Any) -> bool:\n",
    "    # Return True if `value` supports len() and indexing.\n",
    "    try:\n",
    "        _ = len(value)\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        _ = value[0]\n",
    "    except TypeError:\n",
    "        return False\n",
    "    except IndexError:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method `process_args()` processes recorded call arguments, one after the one, until all are minimized or maximized. Processing them individually (rather than, say, all at once) allows to maintain a stable _context_ during reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method also does all the housekeeping, checking arguments and results, and raising errors if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FailureNotReproducedError(ValueError):\n",
    "    pass\n",
    "\n",
    "class NotFailingError(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def check_reproducibility(self) -> None:\n",
    "        # Check whether running the function again fails\n",
    "        assert self.function(), \\\n",
    "            \"No call collected. Use `with dd: func()` first.\"\n",
    "        assert self.args(), \\\n",
    "            \"No arguments collected. Use `with dd: func(args)` first.\"\n",
    "\n",
    "        self.reset()\n",
    "        outcome = self.test(self.args())\n",
    "        if outcome == UNRESOLVED:\n",
    "            raise FailureNotReproducedError(\n",
    "                \"When called again, \" +\n",
    "                self.format_call(self.args()) + \n",
    "                \" raised \" +\n",
    "                self.format_exception(self.last_exception) +\n",
    "                \" instead of \" +\n",
    "                self.format_exception(self.exception()))\n",
    "\n",
    "        if outcome == PASS:\n",
    "            raise NotFailingError(\"When called again, \" +\n",
    "                                  self.format_call(self.args()) + \n",
    "                                  \" did not fail\")\n",
    "        assert outcome == FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def process_args(self, strategy: Callable, **strategy_args: Any) -> \\\n",
    "        Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Reduce all reducible arguments, using `strategy`(var, `strategy_args`).\n",
    "        Can be overloaded in subclasses.\n",
    "        \"\"\"\n",
    "\n",
    "        pass_args = {}  # Local copy\n",
    "        fail_args = {}  # Local copy\n",
    "        diff_args = {}\n",
    "        for var in self.args():\n",
    "            fail_args[var] = self.args()[var]\n",
    "            diff_args[var] = self.args()[var]\n",
    "            pass_args[var] = self.args()[var]\n",
    "\n",
    "            if is_reducible(pass_args[var]):\n",
    "                pass_args[var] = empty(pass_args[var])\n",
    "\n",
    "        vars_to_be_processed = set(fail_args.keys())\n",
    "\n",
    "        pass_processed = 0\n",
    "        fail_processed = 0\n",
    "\n",
    "        self.check_reproducibility()\n",
    "\n",
    "        # We take turns in processing variables until all are processed\n",
    "        while len(vars_to_be_processed) > 0:\n",
    "            for var in vars_to_be_processed:\n",
    "                if not is_reducible(fail_args[var]):\n",
    "                    vars_to_be_processed.remove(var)\n",
    "                    break\n",
    "\n",
    "                if self.log:\n",
    "                    print(f\"Processing {var}...\")\n",
    "\n",
    "                maximized_pass_value, minimized_fail_value, diff = \\\n",
    "                    strategy(var, fail_args, **strategy_args)\n",
    "\n",
    "                if (maximized_pass_value is not None and \n",
    "                    len(maximized_pass_value) > len(pass_args[var])):\n",
    "                    pass_args[var] = maximized_pass_value\n",
    "                    # FIXME: diff_args may not be correct for multiple args\n",
    "                    diff_args[var] = diff\n",
    "                    if self.log:\n",
    "                        print(f\"Maximized {var} to\",\n",
    "                              repr(maximized_pass_value))\n",
    "                    vars_to_be_processed = set(fail_args.keys())\n",
    "                    pass_processed += 1\n",
    "\n",
    "                if (minimized_fail_value is not None and \n",
    "                    len(minimized_fail_value) < len(fail_args[var])):\n",
    "                    fail_args[var] = minimized_fail_value\n",
    "                    diff_args[var] = diff\n",
    "                    if self.log:\n",
    "                        print(f\"Minimized {var} to\",\n",
    "                              repr(minimized_fail_value))\n",
    "                    vars_to_be_processed = set(fail_args.keys())\n",
    "                    fail_processed += 1\n",
    "\n",
    "                vars_to_be_processed.remove(var)\n",
    "                break\n",
    "\n",
    "        assert pass_processed == 0 or self.test(pass_args) == PASS, \\\n",
    "            f\"{self.format_call(pass_args)} does not pass\"\n",
    "        assert fail_processed == 0 or self.test(fail_args) == FAIL, \\\n",
    "            f\"{self.format_call(fail_args)} does not fail\"\n",
    "\n",
    "        if self.log and pass_processed > 0:\n",
    "            print(\"Maximized passing call to\",\n",
    "                  self.format_call(pass_args))\n",
    "        if self.log and fail_processed > 0:\n",
    "            print(\"Minimized failing call to\",\n",
    "                  self.format_call(fail_args))\n",
    "\n",
    "        return pass_args, fail_args, diff_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more housekeeping, we define the `after_collection()` method that will be invoked at the end of the `with` block. It checks for a number of additional preconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def after_collection(self) -> None:\n",
    "        # Some post-collection checks\n",
    "        if self._function is None:\n",
    "            raise NoCallError(\"No function call observed\")\n",
    "        if self.exception() is None:\n",
    "            raise NotFailingError(f\"{self.format_call()} did not raise an exception\")\n",
    "\n",
    "        if self.log:\n",
    "            print(f\"Observed {self.format_call()}\" +\n",
    "                  f\" raising {self.format_exception(self.exception())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Public API\n",
    "\n",
    "We finish the implementation with public methods that allow users to run delta debugging and obtain the diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def min_args(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return 1-minimal arguments.\"\"\"\n",
    "        pass_args, fail_args, diff = self.process_args(self.dd, mode='-')\n",
    "        return fail_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def max_args(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return 1-maximal arguments.\"\"\"\n",
    "        pass_args, fail_args, diff = self.process_args(self.dd, mode='+')\n",
    "        return pass_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def min_arg_diff(self) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"Return 1-minimal difference between arguments.\"\"\"\n",
    "        return self.process_args(self.dd, mode='+-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__repr__()` method returns a string representation of the minimized call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebugger(DeltaDebugger):\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Return a string representation of the minimized call.\"\"\"\n",
    "        return self.format_call(self.min_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Excursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the `DeltaDebugger` works, let us run it on our failing input. The expected usage is as introduced earlier – we wrap the failing function in a `with` block, and then print out the debugger to see the reduced arguments. We see that `DeltaDebugger` easily reduces the arguments to the minimal failure-inducing input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    mystery(failing_input)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn on logging for `DeltaDebugger` to see how it proceeds. With each step, we see how the remaining input gets smaller and smaller, until only two characters remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=True) as dd:\n",
    "    mystery(failing_input)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to access the debugger programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    mystery(failing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.min_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz(\"What happens if the function under test does not raise an exception?\",\n",
    "    [\n",
    "        \"Delta debugging searches for the minimal input\"\n",
    "        \" that produces the same result\",\n",
    "        \"Delta debugging starts a fuzzer to find an exception\",\n",
    "        \"Delta debugging raises an exception\"\n",
    "        \"Delta debugging runs forever in a loop\",\n",
    "    ], '0 ** 0 + 1 ** 0 + 0 ** 1 + 1 ** 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, `DeltaDebugger` checks if an exception occurs. If not, you obtain a `NotFailingError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(NotFailingError):\n",
    "    with DeltaDebugger() as dd:\n",
    "        mystery(\"An input that does not fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta Debugging also assumes that the function under test is _deterministic_. If it occasionally fails and occasionally passes, you will get random results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Let us apply `DeltaDebugger` on a number of examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing remove_html_markup()\n",
    "\n",
    "For our ongoing `remove_html_markup()` example, we can reduce the failure-inducing input to a minimum, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Assertions import remove_html_markup  # minor dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=True) as dd:\n",
    "    remove_html_markup('\"x > y\"')\n",
    "dd.min_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Multiple Arguments\n",
    "\n",
    "If a function has multiple reducible variables, they get reduced in turns. This `string_error()` function fails whenever `s1` is a substring of `s2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_error(s1: str, s2: str) -> None:\n",
    "    assert s1 not in s2, \"no substrings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=True) as dd:\n",
    "    string_error(\"foo\", \"foobar\")\n",
    "dd.min_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the failure also occurs if both variables contain only one (same) character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_error_args = dd.min_args()\n",
    "string_error_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    string_error(string_error_args['s1'], string_error_args['s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides a simple way to turn dictionaries into function calls. The construct\n",
    "\n",
    "```python\n",
    "fun(**args)\n",
    "```\n",
    "\n",
    "invokes the function `fun`, with all parameters assigned from the respective values in the dictionary.\n",
    "You can use this shortcut to invoke an [interactive debugger](Debugger) on the minimized input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Debugger import Debugger  # minor dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import next_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore\n",
    "next_inputs(['print', 'quit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    with Debugger():\n",
    "        string_error(**string_error_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing other Collections\n",
    "\n",
    "Our `DeltaDebugger` is not limited to strings. It can reduce any argument `x` for which a `len(x)` operation and an indexing operation `x[i]` is defined – notably lists. Here is how to apply `DeltaDebugger` on a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_error(l1: List, l2: List, maxlen: int) -> None:\n",
    "    assert len(l1) < len(l2) < maxlen, \"invalid string length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    list_error(l1=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], l2=[1, 2, 3], maxlen=5)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Inputs\n",
    "\n",
    "Sometimes, it may be useful to not _minimize_ the input, but rather _maximize_ it – that is, to find the _maximum_ input that does _not_ fail. For instance, you may have an input of which you want to _preserve_ as much as possible – to repair it, or to establish a _context_ that is as close as possible to the real input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is possible by using the `max_arg()` method. It implements the `ddmax` variant of the general Delta Debugging algorithm \\cite{Kirschner2020}. With each step, it tries to add more and more characters to the passing input until it is _1-maximal_ – that is, any additional character that would be added from the failing input also would cause the function to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=True) as dd:\n",
    "    mystery(failing_input)\n",
    "max_passing_input = dd.max_args()['inp']\n",
    "max_passing_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is precisely the failure-inducing input _except_ for one of the parentheses. Adding this single character would cause the input to cause a failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure-Inducing Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants to look for _differences_ that distinguish passing from failing runs, Delta Debugging also has a direct method for this – by both maximizing the passing input and minimizing the failing input until they meet somewhere in the middle. The remaining difference is what makes the difference between passing and failing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the failure-inducing differences for `mystery()`, use the `min_arg_diff()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=True) as dd:\n",
    "    mystery(failing_input)\n",
    "max_passing_args, min_failing_args, diff = dd.min_arg_diff()\n",
    "max_passing_args['inp'], min_failing_args['inp'], diff['inp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing failure-inducing differences is especially efficient on large inputs, since the number of differences between a passing and a failing input is much smaller than the inputs themselves. Here is the failure-inducing difference as determined by Delta Debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff['inp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Program Code\n",
    "\n",
    "One particularly fun application of reducers is on _program code_. Technically speaking, program code is just another input to a computation; and we can actually automatically determine which minimum of program code is required to produce a failure, using Delta Debugging. Such minimization of code is typically used as it comes to debugging programs that accept code as their input, such as _compilers_ and _interpreters_. However, it can also pinpoint failure causes in the (input) code itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let us apply Delta Debugging on the code from [the chapter on assertions](Assertions.html). You do not need to have read the chapter; the important part is that this chapter provides an implementation of `remove_html_markup()` that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore\n",
    "try:\n",
    "    del remove_html_markup\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Assertions  # minor dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the source code of all the chapter; this is several hundred lines long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertions_source_lines, _ = inspect.getsourcelines(Assertions)\n",
    "# print_content(\"\".join(assertions_source_lines), \".py\")\n",
    "assertions_source_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(assertions_source_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this code and execute it. Nothing particular should happen here, as our imports only import definitions of functions, classes, and global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run(lines: List[str]) -> None:\n",
    "    # To execute 'Assertions' in place, we need to define __name__ and __package__\n",
    "    exec(\"\".join(lines), {'__name__': '<string>',\n",
    "                          '__package__': 'debuggingbook',\n",
    "                          'Any': Any,\n",
    "                         'Type': Type,\n",
    "                         'TracebackType': TracebackType,\n",
    "                         'Optional': Optional},\n",
    "         {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_and_run(assertions_source_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Assertions import remove_html_markup  # minor dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add some code to it – a \"My Test\" assertion that tests that `remove_html_markup()`, applied on a string with double quotes, should keep these in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_test_html_markup_simple(lines: List[str]) -> None:\n",
    "    compile_and_run(lines + \n",
    "        [\n",
    "            '''''',\n",
    "            '''assert remove_html_markup('\"foo\"') == '\"foo\"', \"My Test\"\\n'''\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assertion fails. (As always, `remove_html_markup()` is buggy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    compile_and_test_html_markup_simple(assertions_source_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question we want to address in this section is: Given this assertion, can we automatically determine which part of the `Assertions` code lines in `assertions_source_lines` is relevant for producing the failure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Code Lines\n",
    "\n",
    "Since our `Assertions` source code comes as a list of lines, we can apply our `DeltaDebugger` on it. The result will be the list of source lines that is necessary to make the assertion fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz(\"What will the reduced set of lines contain?\",\n",
    "     [\n",
    "         \"All of the source code in the assertions chapter.\",\n",
    "         \"Only the source code of `remove_html_markup()`\",\n",
    "         \"Only a subset of `remove_html_markup()`\",\n",
    "         \"No lines at all.\"\n",
    "     ], '[x for x in range((1 + 1) ** (1 + 1)) if x % (1 + 1) == 1][1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what the `DeltaDebugger` produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=False) as dd:\n",
    "    compile_and_test_html_markup_simple(assertions_source_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get exactly _four_ lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_lines = dd.min_args()['lines']\n",
    "len(reduced_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import print_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(\"\".join(reduced_lines), \".py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On these lines, our test actually still fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    compile_and_test_html_markup_simple(reduced_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This failure may come as a surprise – `remove_html_markup()` is reduced to a function which does not even return a value. However, this is how it causes our \"My Test\" assertion to fail: In Python, a function without an explicit `return` statement returns `None`. This value is definitely not the string the \"My Test\" assertion expects, so it fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, we also have a function `test_square_root()` which is equally devoid of any meaning – its code line does not even stem from its original implementation. Note, however, how the set of four lines is actually 1-minimal – removing any further line would result in a syntax error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure we do not remove code that actually would be necessary for normal behavior, let us add another check – one that checks for the _normal_ functionality of `remove_html_markup()`. If this one fails (say, after the code has been tampered with too much), it raises an exception – but a _different_ one from the original failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_test_html_markup(lines: List[str]) -> None:\n",
    "    compile_and_run(lines +\n",
    "        [\n",
    "            '''''',\n",
    "            '''if remove_html_markup('<foo>bar</foo>') != 'bar':\\n''',\n",
    "            '''    raise RuntimeError(\"Missing functionality\")\\n''',\n",
    "            '''assert remove_html_markup('\"foo\"') == '\"foo\"', \"My Test\"\\n'''\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On our \"reduced\" code, we now obtain a different exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    compile_and_test_html_markup(reduced_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such an outcome that is different from the original failure causes our `DeltaDebugger` not treating this as a failure, but rather as a `UNRESOLVED` outcome, indicating that the test cannot determine whether it passed or failed. The `ddmin` algorithm treats such unresolved outcomes as if they were passing; hence, the algorithm treats its minimization attempt as unsuccessful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this change things? When we reduce the `Assertions` source code with the extended assertions, we now get a different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=False) as dd:\n",
    "    compile_and_test_html_markup(assertions_source_lines)\n",
    "reduced_assertions_source_lines = dd.min_args()['lines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result actually is the source code of `remove_html_markup()` – and _only_ the source code. This is a success, as Delta Debugging has eliminated all the other parts of the `Assertions` source code; these neither contribute to the correct functioning of `remove_html_markup()`, nor to the failure at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(\"\".join(reduced_assertions_source_lines), \".py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, we have reduced the number of relevant lines in `Assertions` to about 3% of the original source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduced_assertions_source_lines) / len(assertions_source_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The astute reader may notice that `remove_html_markup()`, as shown above, is slightly different from the original version in the [chapter on assertions](Assertions.ipynb). Here's the original version for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_markup_source_lines, _ = inspect.getsourcelines(Assertions.remove_html_markup)\n",
    "print_content(\"\".join(remove_html_markup_source_lines), \".py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz(\"In the reduced version, what has changed?\",\n",
    "    [\n",
    "        \"Comments are deleted\",\n",
    "        \"Blank lines are deleted\",\n",
    "        \"Initializations are deleted\",\n",
    "        \"The assertion is deleted\",\n",
    "    ], '[(1 ** 0 - -1 ** 0) ** n for n in range(0, 3)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, Delta Debugging has determined all these as being irrelevant for reproducing the failure – and consequently, has deleted them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Code Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reduce the code further by removing individual _characters_ rather than lines. To this end, we convert our (already reduced) `remove_html_markup()` code into a list of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_assertions_source_characters = list(\"\".join(reduced_assertions_source_lines))\n",
    "print(reduced_assertions_source_characters[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `compile_and_ttest_html_markup()` works (and fails) as before: It still joins the given strings into one and executes them. (Remember that in Python, \"characters\" are simply strings of length one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    compile_and_test_html_markup(reduced_assertions_source_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what Delta Debugging makes of that – and also, how long it takes. The `Timer` class gives us a simple means to measure time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger(log=False) as dd:\n",
    "    compile_and_test_html_markup(reduced_assertions_source_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the reduced result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    further_reduced_assertions_source_characters = dd.min_args()['lines']\n",
    "print_content(\"\".join(further_reduced_assertions_source_characters), \".py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a number of observations we can make about this code.\n",
    "\n",
    "* All superfluous blanks and even newlines have been removed.\n",
    "* As a curiosity, the initialization of `tag` and `quote` to `False` is now merged into a single (semantics-preserving) statement.\n",
    "* The semantics and effect of `<` and `>` characters is preserved, as mandated by our `RuntimeError` check.\n",
    "* Double quotes still have the effect of not being included in the returned value: the remaining `quote` has no effect.\n",
    "\n",
    "Semantics-wise, this reduced variant still yields the \"original\" failure; the biggest semantic differences, though, are in the condition and code associated with double quotes – which actually also is the location of the defect to be fixed. This is how reducing code can also point to not only _necessary_ locations, but also _defective_ locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind you that reducing code is not cheap, and especially not if you remove by characters. It has taken `DeltaDebugger` several thousand tests to obtain the result above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to do so, it even required _several seconds_. This may be little for a human, but from a CPU standpoint, this is an enormous effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Syntax Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reducing code (or generally speaking, recursive structures), using a _syntactic_ approach can be a much better alternative to the _line-by-line_ or _character-by-character_ approaches discussed above. The idea is that one represents the input as a _tree_ (rather than a sequence of strings), in which a reducer would work on entire subtrees, deleting or reducing parts of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate this concept on _syntax trees_ representing Python code. Python provides us with simple means to interactively convert code into syntax trees (and back again). So, in order to reduce code, we can\n",
    "\n",
    "1. _parse_ the program code into a syntax tree (called *abstract syntax tree* or *AST*);\n",
    "2. reduce the syntax tree to a minimum, executing it to test reductions; and\n",
    "3. _unparse_ the tree to obtain textual code again.\n",
    "\n",
    "Since transformations on the AST are much less likely to produce syntax errors, reducing ASTs is much more efficient than reducing program code as text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top, an AST also offers additional possibilities for reducing. Notably, instead of just _deleting_ code fragments, we can also _replace_ them with simpler fragments. For instance, we can replace arithmetic expressions with constants, or conditional statements `if cond: body` with the associated body `body`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate how this works, again choosing `remove_html_markup()` as our ongoing example. One more time, we create a function with associated test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_source = inspect.getsource(remove_html_markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(fun_source, '.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Code to Syntax Trees\n",
    "\n",
    "Let us parse this piece of code into an AST. This is done by the `ast.parse()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_tree: ast.Module = ast.parse(fun_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed tree contains the function definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookutils import show_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ast(fun_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add some tests to this, using the same scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = (\n",
    "    '''if remove_html_markup('<foo>bar</foo>') != 'bar':\\n''' +\n",
    "    '''    raise RuntimeError(\"Missing functionality\")\\n''' +\n",
    "    '''assert remove_html_markup('\"foo\"') == '\"foo\"', \"My Test\"'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree: ast.Module = ast.parse(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(astor.to_source(test_tree), '.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge the function definition tree and the test tree into a single one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_test_tree = copy.deepcopy(fun_tree)\n",
    "fun_test_tree.body += test_tree.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a tree can be compiled into a code object, using Python's `compile()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_test_code = compile(fun_test_tree, '<string>', 'exec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting code object can be executed directly, using the Python `exec()` function. We see that our test fails as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    exec(fun_test_code, {}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traversing Syntax Trees\n",
    "\n",
    "Our goal is now to reduce this tree (or at least the subtree with the function definition) to a minimum. \n",
    "To this end, we manipulate the AST through the Python modules `ast` and `astor`. The [official Python `ast` reference](http://docs.python.org/3/library/ast) is complete, but a bit brief; the documentation [\"Green Tree Snakes - the missing Python AST docs\"](https://greentreesnakes.readthedocs.io/en/latest/) provides an excellent introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two means for exploring and changing ASTs are the classes `NodeVisitor` and `NodeTransformer`, respectively. We start with creating a list of all nodes in the tree, using a `NodeVisitor` subclass.\n",
    "\n",
    "Its `visit()` method is called for every node in the tree, which we achieve by having it return `self.generic_visit()` for the current node. It saves all visited nodes in the `_all_nodes` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import NodeTransformer, NodeVisitor, fix_missing_locations, AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeCollector(NodeVisitor):\n",
    "    \"\"\"Collect all nodes in an AST.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._all_nodes: List[AST] = []\n",
    "\n",
    "    def generic_visit(self, node: AST) -> None:\n",
    "        self._all_nodes.append(node)\n",
    "        return super().generic_visit(node)\n",
    "\n",
    "    def collect(self, tree: AST) -> List[AST]:\n",
    "        \"\"\"Return a list of all nodes in tree.\"\"\"\n",
    "        self._all_nodes = []\n",
    "        self.visit(tree)\n",
    "        return self._all_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our `NodeCollector()` class produces a list of all nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_nodes = NodeCollector().collect(fun_tree)\n",
    "len(fun_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_nodes[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a list of nodes is what we can feed into Delta Debugging in order to reduce it. The idea is that with every test, we take the tree and for each node in the tree, we check whether it is still in the list – if not, we remove it. Thus, by reducing the list of nodes, we simultaneously reduce the tree as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Nodes\n",
    "\n",
    "In our next step, we write some code that, given such a list of nodes, _prunes_ the tree such that _only_ elements in the list are still contained. To this end, we proceed in four steps:\n",
    "\n",
    "1. We traverse the original AST, _marking_ all nodes as \"to be deleted\".\n",
    "2. We traverse the given list of nodes, clearing their markers.\n",
    "3. We copy the original tree (including the markers) into a new tree – the one to be reduced.\n",
    "4. We traverse the new tree, now deleting all marked nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we go through such an extra effort? The reason is that our list of nodes contains references into the _original_ tree – a tree that needs to stay unchanged such that we can reuse it for later. The new tree (the copy) has the same nodes, but at different addresses, so our original references cannot be used anymore. Markers, however, just like any other attributes, are safely copied from the original into the new tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NodeMarker()` visitor marks all nodes in a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeMarker(NodeVisitor):\n",
    "    def visit(self, node: AST) -> AST:\n",
    "        node.marked = True  # type: ignore\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NodeReducer()` transformer reduces all marked nodes. If a method `visit_<node class>()` is defined, it will be invoked; otherwise, `visit_Node()` is invoked, which _deletes_ the node (and its subtree) by returning `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeReducer(NodeTransformer):\n",
    "    def visit(self, node: AST) -> Any:\n",
    "        method = 'visit_' + node.__class__.__name__\n",
    "        visitor = getattr(self, method, self.visit_Node)\n",
    "        return visitor(node)\n",
    "\n",
    "    def visit_Module(self, node: AST) -> Any:\n",
    "        # Can't remove modules\n",
    "        return super().generic_visit(node)\n",
    "\n",
    "    def visit_Node(self, node: AST) -> Any:\n",
    "        \"\"\"Default visitor for all nodes\"\"\"\n",
    "        if node.marked:  # type: ignore\n",
    "            return None  # delete it\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function `copy_and_reduce()` puts these pieces together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_reduce(tree: AST, keep_list: List[AST]) -> AST:\n",
    "    \"\"\"Copy tree, reducing all nodes that are not in keep_list.\"\"\"\n",
    "\n",
    "    # Mark all nodes except those in keep_list\n",
    "    NodeMarker().visit(tree)\n",
    "    for node in keep_list:\n",
    "        # print(\"Clearing\", node)\n",
    "        node.marked = False  # type: ignore\n",
    "\n",
    "    # Copy tree and delete marked nodes\n",
    "    new_tree = copy.deepcopy(tree)\n",
    "    NodeReducer().visit(new_tree)\n",
    "    return new_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply this in practice. We take the first assignment in our tree..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_nodes[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... whose subtree happens to be the assignment to `tag`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astor.to_source(fun_nodes[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep all nodes _except_ for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = fun_nodes.copy()\n",
    "del keep_list[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create a copy of the tree in which the assignment is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fun_tree = cast(ast.Module, copy_and_reduce(fun_tree, keep_list))\n",
    "show_ast(new_fun_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new tree no longer contains the initial assignment to `tag`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(astor.to_source(new_fun_tree), '.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add our tests and then execute this code, we get an error, as `tag` is now no longer initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fun_tree.body += test_tree.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_code = compile(new_fun_tree, \"<string>\", 'exec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(UnboundLocalError):\n",
    "    exec(fun_code, {}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have _no_ node in the keep list, the whole tree gets deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_tree = copy_and_reduce(fun_tree, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astor.to_source(empty_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Trees\n",
    "\n",
    "We can put all these steps together in a single function. `compile_and_test_ast()` takes a tree and a list of nodes, reduces the tree to those nodes in the list, and then compiles and runs the reduced AST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_test_ast(tree: ast.Module, keep_list: List[AST], \n",
    "                         test_tree: Optional[ast.Module] = None) -> None:\n",
    "    new_tree = cast(ast.Module, copy_and_reduce(tree, keep_list))\n",
    "    # print(astor.to_source(new_tree))\n",
    "\n",
    "    if test_tree is not None:\n",
    "        new_tree.body += test_tree.body\n",
    "\n",
    "    try:\n",
    "        code_object = compile(new_tree, '<string>', 'exec')\n",
    "    except Exception:\n",
    "        raise SyntaxError(\"Cannot compile\")\n",
    "\n",
    "    exec(code_object, {}, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(AssertionError):\n",
    "    compile_and_test_ast(fun_tree, fun_nodes, test_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run our delta debugger on the AST, this is the list of remaining nodes we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    compile_and_test_ast(fun_tree, fun_nodes, test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_nodes = dd.min_args()['keep_list']\n",
    "len(reduced_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the associated tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_fun_tree = copy_and_reduce(fun_tree, reduced_nodes)\n",
    "show_ast(reduced_fun_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is its textual representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_content(astor.to_source(reduced_fun_tree), '.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some code was deleted – notably the assertion at the end – but otherwise, our deletion strategy was not particularly effective. This is because in Python, one cannot simply delete the single statement in a controlled body – this raises a syntax error. One would have to replace it with `pass` (or some other statement with no effect) to stay syntactically valid. Still, the syntax-based reduction would still single out `remove_html_markup()` from the `Assertions` source code – and do so even faster, as it would apply on one definition (rather than one line) after another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Nodes\n",
    "\n",
    "To further boost our syntactic reduction strategy, we implement a set of additional reduction operators. First, as already discussed, we do not simply delete an assignment, but we replace it with a `pass` statement. To obtain the tree for `pass`, we simply parse it and access the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeReducer(NodeReducer):\n",
    "    PASS_TREE = ast.parse(\"pass\").body[0]\n",
    "\n",
    "    def visit_Assign(self, node: ast.Assign) -> AST:\n",
    "        if node.marked:  # type: ignore\n",
    "            # Replace by pass\n",
    "            return self.PASS_TREE\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, we can replace comparison operators with `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeReducer(NodeReducer):\n",
    "    FALSE_TREE = ast.parse(\"False\").body[0].value  # type: ignore\n",
    "\n",
    "    def visit_Compare(self, node: ast.Compare) -> AST:\n",
    "        if node.marked:  # type: ignore\n",
    "            # Replace by False\n",
    "            return self.FALSE_TREE\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a Boolean operator, we attempt to replace it with its left operand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeReducer(NodeReducer):\n",
    "    def visit_BoolOp(self, node: ast.BoolOp) -> AST:\n",
    "        if node.marked:  # type: ignore\n",
    "            # Replace by left operator\n",
    "            return node.values[0]\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we find an `If` clause, we attempt to replace it by its body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeReducer(NodeReducer):\n",
    "    def visit_If(self, node: ast.If) -> Union[AST, List[ast.stmt]]:\n",
    "        if node.marked:  # type: ignore\n",
    "            # Replace by body\n",
    "            return node.body\n",
    "        return super().generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to reduce our code with these additional reducers enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    compile_and_test_ast(fun_tree, fun_nodes, test_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reduced code we get. We see that all references to `quote` have gone, as has the handling of single quotes – none of this is relevant for the failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_nodes = dd.min_args()['keep_list']\n",
    "reduced_fun_tree = copy_and_reduce(fun_tree, reduced_nodes)\n",
    "print_content(astor.to_source(reduced_fun_tree), '.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the best insights come from comparing this reduced version to the original implementation – and we learn that the problem is not related to the `quote` variable, or to the handling of single quotes; the problem is simply that when the input contains double quotes, these are not added to the final string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our reduction code, however, we only touch the surface of what could actually be possible. So far, we implement exactly one reduction per node – but of course, there are many alternatives an expression or statement could be reduced to. We will explore some of these in the [exercises](#Exercises), below; also be sure to check out the [background](#Background) on code reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "A _reducer_ takes a failure-inducing input and reduces it to the minimum that still reproduces the failure.  This chapter provides a `DeltaDebugger` class that implements such a reducer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example: An arithmetic expression causes an error in the Python interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myeval(inp: str) -> Any:\n",
    "    return eval(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError(ZeroDivisionError):\n",
    "    myeval('1 + 2 * 3 / 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we reduce this input to a minimum? _Delta Debugging_ is a simple and robust reduction algorithm. We provide a `DeltaDebugger` class that is used in conjunction with a (failing) function call:\n",
    "\n",
    "```python\n",
    "with DeltaDebugger() as dd:\n",
    "    fun(args...)\n",
    "dd\n",
    "```\n",
    "\n",
    "The class automatically determines minimal arguments that cause the function to fail with the same exception as the original. Printing out the class object reveals the minimized call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeltaDebugger() as dd:\n",
    "    myeval('1 + 2 * 3 / 0')\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is reduced to the maximum: We get the essence of the division by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also is an interface to access the reduced input(s) programmatically. The method `min_args()` returns a dictionary in which all function arguments are minimized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.min_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, `max_args()` returns a dictionary in which all function arguments are maximized, but still pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.max_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `min_arg_diff()` returns a triple of \n",
    "* passing input,\n",
    "* failing input, and\n",
    "* their minimal failure-inducing difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.min_arg_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also access the function itself, as well as its original arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.function().__name__, dd.args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DeltaDebugger` processes (i.e., minimizes or maximizes) all arguments that support a `len()` operation and that can be indexed – notably _strings_ and _lists_. If a function has multiple arguments, all arguments that can be processed will be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter also provides a number of superclasses to `DeltaDebugger`, notably `CallCollector`, which obtains the first function call for `DeltaDebugger`. `CallReducer` classes allow for implementing alternate call reduction strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore\n",
    "from ClassDiagram import display_class_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore\n",
    "display_class_hierarchy([DeltaDebugger],\n",
    "                        public_methods=[\n",
    "                            StackInspector.caller_frame,\n",
    "                            StackInspector.caller_function,\n",
    "                            StackInspector.caller_globals,\n",
    "                            StackInspector.caller_locals,\n",
    "                            StackInspector.caller_location,\n",
    "                            StackInspector.search_frame,\n",
    "                            StackInspector.search_func,\n",
    "                            StackInspector.is_internal_error,\n",
    "                            StackInspector.our_frame,\n",
    "                            CallCollector.__init__,\n",
    "                            CallCollector.__enter__,\n",
    "                            CallCollector.__exit__,\n",
    "                            CallCollector.function,\n",
    "                            CallCollector.args,\n",
    "                            CallCollector.exception,\n",
    "                            CallCollector.call,\n",
    "                            CallReducer.__init__,\n",
    "                            CallReducer.reduce_arg,\n",
    "                            DeltaDebugger.dd,\n",
    "                            DeltaDebugger.min_args,\n",
    "                            DeltaDebugger.max_args,\n",
    "                            DeltaDebugger.min_arg_diff,\n",
    "                            DeltaDebugger.__repr__\n",
    "                        ],\n",
    "                        project='debuggingbook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Reducing failure-inducing inputs to a minimum is helpful for testing and debugging.\n",
    "* _Delta debugging_ is a simple and robust algorithm to easily reduce inputs of test cases, as well as their code.\n",
    "* Precisely specifying failure conditions helps avoiding false diagnoses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "Our next chapter focuses on [finding _failure-inducing code changes_](ChangeDebugger.ipynb), using delta debugging and version control systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The \"lexical\" delta debugging algorithm discussed here – both in its simplifying `ddmin` as well as in its general `dd` form – stem from \\cite{Zeller2002}; actually, `ddmin` is the exact Python implementation as used by Zeller in 2002. The `ddmax` variant was first evaluated in \\cite{Kirschner2020}. This chapter is the first to show how both `ddmin` and `ddmax` can be implemented as small variations of `dd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of systematically reducing inputs has been discovered a number of times, although not as  automatic and generic as delta debugging. \\cite{Slutz1998}, for instance, discusses systematic reduction of SQL statements for SQL databases; the general process as manual work is well described by \\cite{Kernighan1999}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deficits of delta debugging as it comes to syntactically complex inputs were first discussed in *compiler testing*, and _reducing tree inputs_ rather than string inputs was quickly discovered as an alternative.  *Hierarchical Delta Debugging* (*HDD*) \\cite{Misherghi2006} applies delta debugging on subtrees of a parse tree, systematically reducing a parse tree to a minimum.  _Generalized Tree Reduction_ \\cite{Herfert2017} generalizes this idea to apply arbitrary _patterns_ such as replacing a term by a compatible term in a subtree.  Using _grammars_ to reduce inputs was first implemented in the _Perses_ tool \\cite{Sun2018}. [A Python implementation of grammar-based input reduction](https://www.fuzzingbook.org/html/Reducer.html#Grammar-Based-Input-Reduction) is part of \"The Fuzzing Book\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While applying delta debugging to code lines does a decent job, _syntactic_ and especially _language-specific_ approaches can do a much better job for the programming language at hand:\n",
    "\n",
    "* *C-Reduce* \\cite{Regehr2012} is a reducer specifically targeting the reduction of programming languages.  Besides reductions in the style of delta debugging or tree transformations, C-Reduce comes with more than 30 source-to-source transformations that replace aggregates by scalars, remove function parameters at a definition and all call sites, change functions to return `void` and deleting all `return` statements, and many more.  While specifically instantiated for the C language (and used for testing C compilers), these principles extend to arbitrary programming languages following an ALGOL-like syntax.\n",
    "\n",
    "* Kalhauge and Palsberg \\cite{Kalhauge2019} introduce *binary reduction of dependency graphs*, a general solution for reducing arbitrary inputs with dependencies. Their *J-Reduce* tool specifically targets Java programs, and again is much faster than delta debugging and achieves a higher reduction rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [blog post](https://www.drmaciver.com/2019/01/notes-on-test-case-reduction/) by David McIver contains lots of insights on how to apply reduction in practice, in particular multiple runs with different abstraction levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "How to best reduce inputs is still an underdeveloped field of research, with lots of opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 1: Advanced Syntactic Code Reduction\n",
    "\n",
    "Extend the code in [\"Transforming Nodes\"](#Transforming-Nodes) such that _multiple_ reduction possibilities for a node are being considered. For instance:\n",
    "\n",
    "* Replace a `BoolOp` node by `True`.\n",
    "* Replace a `BoolOp` node by `False`.\n",
    "* Replace a `BoolOp` node by its left operand.\n",
    "* Replace a `BoolOp` node by its right operand.\n",
    "\n",
    "or:\n",
    "\n",
    "* Replace an `If` node by its \"then\" body.\n",
    "* Replace an `If` node by its \"else\" body.\n",
    "\n",
    "or:\n",
    "\n",
    "* Replace all instances of a variable by a constant.\n",
    "\n",
    "or:\n",
    "\n",
    "* Replace expressions by a constant.\n",
    "\n",
    "Have a look at the [official Python `ast` reference](http://docs.python.org/3/library/ast) for a list of nodes (and some ideas on what to replace them by). The documentation [\"Green Tree Snakes - the missing Python AST docs\"](https://greentreesnakes.readthedocs.io/en/latest/) provides an excellent introduction on visitors and transformers. Make copious use of AST visualization and tests to ensure your syntax trees are still correct.\n",
    "\n",
    "Strategy-wise, you should first create a list of _possible_ reductions; and then pass to Delta Debugging a \"keep list\" of reductions that should _not_ be applied. When Delta Debugging minimizes this list, it will apply as many reductions as possible."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
